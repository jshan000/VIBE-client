import React, { useState, useEffect } from 'react';
import { View, Text, StyleSheet, TouchableOpacity, PermissionsAndroid, Platform, Vibration, Alert } from 'react-native';
import AudioRecorderPlayer from 'react-native-audio-recorder-player';
import axios from 'axios';
import HapticFeedback from 'react-native-haptic-feedback';
import { NavigationContainer } from '@react-navigation/native';
import { createStackNavigator } from '@react-navigation/stack';

const audioRecorderPlayer = new AudioRecorderPlayer();
const Stack = createStackNavigator();

const App = () => {
  return (
    <NavigationContainer>
      <Stack.Navigator initialRouteName="Splash">
        <Stack.Screen name="Splash" component={SplashScreen} options={{ headerShown: false }} />
        <Stack.Screen name="Main" component={MainScreen} options={{ headerShown: false }} />
        <Stack.Screen name="Recording" component={RecordingScreen} options={{ title: 'ì†Œë¦¬ ë¶„ì„' }} />
      </Stack.Navigator>
    </NavigationContainer>
  );
};

// 1. ë¡œê³  í˜ì´ì§€ (Splash Screen)
const SplashScreen = ({ navigation }) => {
  useEffect(() => {
    const timer = setTimeout(() => {
      navigation.replace('Main');  // ë¡œë”© í›„ ë©”ì¸ í™”ë©´ìœ¼ë¡œ ì´ë™
    }, 2000);  // 2ì´ˆ ë¡œë”© ì‹œê°„

    return () => clearTimeout(timer);
  }, [navigation]);

  return (
    <View style={styles.container}>
      <Text style={styles.title}>VIBE</Text>
    </View>
  );
};

// 2. ë©”ì¸ í˜ì´ì§€
const MainScreen = ({ navigation }) => {
  return (
    <View style={styles.container}>
      <Text style={styles.title}>VIBE</Text>
      <TouchableOpacity style={styles.startButton} onPress={() => navigation.navigate('Recording')}>
        <Text style={styles.startButtonText}>ì™¸ì¶œ ì‹œì‘í•˜ê¸°</Text>
      </TouchableOpacity>
    </View>
  );
};

// 3. ë…¹ìŒ ë° ë°ì‹œë²¨ ì‹œê°í™” í˜ì´ì§€
const RecordingScreen = () => {
  const [isRecording, setIsRecording] = useState(false);
  const [decibelLevel, setDecibelLevel] = useState(0);
  const [alertMessage, setAlertMessage] = useState<string | null>(null);

  const onStartRecord = async () => {
    const hasPermission = await requestMicrophonePermission();
    if (!hasPermission) {
      Alert.alert("Permission Required", "ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì •ì—ì„œ ê¶Œí•œì„ í—ˆìš©í•´ ì£¼ì„¸ìš”.");
      return;
    }

    setIsRecording(true);
    setAlertMessage(null);  // ì´ˆê¸°í™”
    await audioRecorderPlayer.startRecorder();

    audioRecorderPlayer.addRecordBackListener((e) => {
      const currentDecibel = e.currentMetering || 0;
      setDecibelLevel(currentDecibel);

      // ë°±ì—”ë“œì— ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì „ì†¡í•˜ê³  ë¶„ì„ ìš”ì²­
      sendDecibelToBackend(currentDecibel);
      return;
    });
  };

  const onStopRecord = async () => {
    setIsRecording(false);
    await audioRecorderPlayer.stopRecorder();
    audioRecorderPlayer.removeRecordBackListener();
  };

  const sendDecibelToBackend = async (decibel: number) => {
    try {
      const response = await axios.post('http://<server-ip>:5000/analyze-audio', { decibel });
      const { alert, message } = response.data;
      if (alert) {
        setAlertMessage(message);
        HapticFeedback.trigger("notificationWarning");
        Vibration.vibrate(500);  // ì§„ë™ 0.5ì´ˆ
      } else {
        setAlertMessage(null);  // ê²½ê³  í•´ì œ
      }
    } catch (error) {
      console.error('Error in analysis:', error);
    }
  };

  // ë°ì‹œë²¨ ìƒíƒœì— ë”°ë¥¸ ë°°ê²½ ìƒ‰ìƒ ì„¤ì •
  const getBackgroundColor = () => {
    if (decibelLevel < 50) {
      return '#00FF00'; // ì•ˆì „ (ì´ˆë¡)
    } else if (decibelLevel >= 50 && decibelLevel < 80) {
      return '#FFFF00'; // ê²½ê³  (ë…¸ë‘)
    } else {
      return '#FF0000'; // ìœ„í—˜ (ë¹¨ê°•)
    }
  };

  // ë°ì‹œë²¨ ìƒíƒœì— ë”°ë¥¸ ë©”ì‹œì§€ ì„¤ì •
  const getStatusMessage = () => {
    if (decibelLevel < 50) {
      return 'ì•ˆì „í•œ ì£¼ë³€ ì†ŒìŒì…ë‹ˆë‹¤';
    } else if (decibelLevel >= 50 && decibelLevel < 80) {
      return 'ì£¼ì˜! ì£¼ë³€ì— ê²½ê³ ìŒì´ ë“¤ë¦½ë‹ˆë‹¤';
    } else {
      return 'ìœ„í—˜í•œ ì†ŒìŒì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤! ì£¼ì˜í•˜ì„¸ìš”!';
    }
  };

  return (
    <View style={[styles.container, { backgroundColor: getBackgroundColor() }]}>
      <TouchableOpacity style={styles.micButton} onPress={isRecording ? onStopRecord : onStartRecord}>
        <Text style={styles.micIcon}>{isRecording ? 'ğŸ›‘' : 'ğŸ§'}</Text>
      </TouchableOpacity>
      <Text style={styles.decibelText}>í˜„ì¬ ë°ì‹œë²¨: {decibelLevel} dB</Text>
      <Text style={styles.statusMessage}>{getStatusMessage()}</Text>
      {alertMessage && <Text style={styles.alert}>{alertMessage}</Text>}
    </View>
  );
};

// ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ í•¨ìˆ˜
async function requestMicrophonePermission() {
  if (Platform.OS === 'android') {
    const granted = await PermissionsAndroid.request(
      PermissionsAndroid.PERMISSIONS.RECORD_AUDIO,
      {
        title: 'Microphone Permission',
        message: 'This app needs access to your microphone for sound analysis.',
        buttonNeutral: 'Ask Me Later',
        buttonNegative: 'Cancel',
        buttonPositive: 'OK',
      }
    );
    return granted === PermissionsAndroid.RESULTS.GRANTED;
  }
  return true;
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
  },
  title: {
    fontSize: 52,
    fontWeight: 'bold',
  },
  startButton: {
    marginTop: 20,
    paddingVertical: 10,
    paddingHorizontal: 20,
    backgroundColor: '#000',
    borderRadius: 5,
  },
  startButtonText: {
    color: '#FFF',
    fontSize: 16,
  },
  micButton: {
    width: 100,
    height: 100,
    borderRadius: 50,
    backgroundColor: '#e0e0e0',
    justifyContent: 'center',
    alignItems: 'center',
    marginBottom: 20,
  },
  micIcon: {
    fontSize: 40,
  },
  decibelText: {
    fontSize: 18,
    fontWeight: '600',
    marginVertical: 10,
  },
  statusMessage: {
    fontSize: 18,
    fontWeight: 'bold',
  },
  alert: {
    marginTop: 20,
    fontSize: 18,
    color: 'red',
    fontWeight: 'bold',
  },
});

export default App;
